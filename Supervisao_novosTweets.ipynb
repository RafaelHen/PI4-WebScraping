{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando biblioteca Pandas para a criação e manipulação de DataFrames.\n",
    "import pandas as pd\n",
    "\n",
    "# Importando o Numpy.\n",
    "import numpy as np\n",
    "\n",
    "# Importando o método PLT para visualizar graficamente os dados, cálculos e regressões que aplicarmos.\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Importando modelos para a realização dos testes de treino.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Importando métricas de avaliações para os modelos.\n",
    "from sklearn.metrics import confusion_matrix, f1_score, auc, roc_auc_score, roc_curve\n",
    "\n",
    "# Importando o método de validação cruzada K-Fold, pontuação do modelo e o separador de dados para treino e teste.\n",
    "from sklearn.model_selection import KFold, cross_val_score,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset de dados de treino da vetorização TF:\n",
    "dados_treino_idf = pd.read_csv(\"tweets_vetorizados_tf_agrupados.csv\", sep=\",\", header=None)\n",
    "dados_treino_idf.head()\n",
    "\n",
    "# Separação dos dados:\n",
    "dados_treino_idf.columns = [dados_treino_idf.loc[0]]\n",
    "dados_treino_idf = dados_treino_idf.drop(dados_treino_idf.index [[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset de dados de treino da vetorização IDF:\n",
    "dados_treino_idf = pd.read_csv(\"tweets_vetorizados_idf_agrupados.csv\", sep=\",\", header=None)\n",
    "dados_treino_idf.head()\n",
    "\n",
    "# Separação dos dados:\n",
    "dados_treino_idf.columns = [dados_treino_idf.loc[0]]\n",
    "dados_treino_idf = dados_treino_idf.drop(dados_treino_idf.index [[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset de dados de treino da vetorização TF_IDF:\n",
    "dados_treino_tf_idf = pd.read_csv(\"vetorizacao_tf_idf.csv\", sep=\",\", header=None)\n",
    "dados_treino_tf_idf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regressão Logística (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "dados_treino_tf.columns = [dados_treino_tf.loc[0]]\n",
    "dados_treino_tf = dados_treino_tf.drop(dados_treino_tf.index [[0]])\n",
    "\n",
    "X = dados_treino_tf.drop(['Cluster'], axis=1).values\n",
    "y = dados_treino_tf['Cluster'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo de Regressão Logística:\n",
    "model = LogisticRegression(penalty = 'l2', C = 1e42, solver = 'liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "lr_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da validação cruzada K-Fold:\n",
    "kfold_validation = KFold(10)\n",
    "result = cross_val_score(model, X_test, y_test, cv = kfold_validation)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', result)\n",
    "print('\\nMédia dos resultados:', np.mean(result))\n",
    "print('\\nPredições feitas:\\n', lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "c_matrix = confusion_matrix(y, model.predict(X))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', c_matrix[0, 0] / sum(c_matrix[0, :]), '\\n')\n",
    "print('Precisão (Precision): ', c_matrix[0, 0] / sum(c_matrix[:, 0]), '\\n')\n",
    "print('Especificidade (Specificity): ', c_matrix[1, 1] / sum(c_matrix[1, :]), '\\n')\n",
    "print('F1 Macro: ', f1_score(y, model.predict(X), average='macro'), '\\n')\n",
    "print('F1 Micro: ', f1_score(y, model.predict(X), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "dados_treino_idf.columns = [dados_treino_idf.loc[0]]\n",
    "dados_treino_idf = dados_treino_tf.drop(dados_treino_idf.index [[0]])\n",
    "\n",
    "X = dados_treino_tf.drop(['Cluster'], axis=1).values\n",
    "y = dados_treino_tf['Cluster'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo de Regressão Logística:\n",
    "model = LogisticRegression(penalty = 'l2', C = 1e42, solver = 'liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "lr_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da validação cruzada K-Fold:\n",
    "kfold_validation = KFold(10)\n",
    "result = cross_val_score(model, X_test, y_test, cv = kfold_validation)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', result)\n",
    "print('\\nMédia dos resultados:', np.mean(result))\n",
    "print('\\nPredições feitas:\\n', lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "c_matrix = confusion_matrix(y, model.predict(X))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', c_matrix[0, 0] / sum(c_matrix[0, :]), '\\n')\n",
    "print('Precisão (Precision): ', c_matrix[0, 0] / sum(c_matrix[:, 0]), '\\n')\n",
    "print('Especificidade (Specificity): ', c_matrix[1, 1] / sum(c_matrix[1, :]), '\\n')\n",
    "print('F1 Macro: ', f1_score(y, model.predict(X), average='macro'), '\\n')\n",
    "print('F1 Micro: ', f1_score(y, model.predict(X), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "dados_treino_tf_idf.columns = [dados_treino_tf.loc[0]]\n",
    "dados_treino_tf_idf = dados_treino_tf.drop(dados_treino_tf.index [[0]])\n",
    "\n",
    "X = dados_treino_tf.drop(['Cluster'], axis=1).values\n",
    "y = dados_treino_tf['Cluster'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo de Regressão Logística:\n",
    "model = LogisticRegression(penalty = 'l2', C = 1e42, solver = 'liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "lr_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da validação cruzada K-Fold:\n",
    "kfold_validation = KFold(10)\n",
    "result = cross_val_score(model, X_test, y_test, cv = kfold_validation)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', result)\n",
    "print('\\nMédia dos resultados:', np.mean(result))\n",
    "print('\\nPredições feitas:\\n', lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "c_matrix = confusion_matrix(y, model.predict(X))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', c_matrix[0, 0] / sum(c_matrix[0, :]), '\\n')\n",
    "print('Precisão (Precision): ', c_matrix[0, 0] / sum(c_matrix[:, 0]), '\\n')\n",
    "print('Especificidade (Specificity): ', c_matrix[1, 1] / sum(c_matrix[1, :]), '\\n')\n",
    "print('F1 Macro: ', f1_score(y, model.predict(X), average='macro'), '\\n')\n",
    "print('F1 Micro: ', f1_score(y, model.predict(X), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "X = dadosTreinoBalanceados.drop([85], axis=1)\n",
    "y = dadosTreinoBalanceados[85]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo kNN:\n",
    "model = KNeighborsClassifier(n_neighbors=20)\n",
    "model.fit(X_train, y_train)\n",
    "knn_pred = model.predict(X)\n",
    "\n",
    "# Aplicação da validação cruzada K-Fold:\n",
    "kfold_validation = KFold(10)\n",
    "result = cross_val_score(model, X_test, y_test, cv = kfold_validation)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', result)\n",
    "print('\\nMédia dos resultados:', np.mean(result))\n",
    "print('\\nPredições feitas:\\n', knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "c_matrix = confusion_matrix(y, model.predict(X))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', c_matrix[0, 0] / sum(c_matrix[0, :]), '\\n')\n",
    "print('Precisão (Precision): ', c_matrix[0, 0] / sum(c_matrix[:, 0]), '\\n')\n",
    "print('Especificidade (Specificity): ', c_matrix[1, 1] / sum(c_matrix[1, :]), '\\n')\n",
    "print('F1 Macro: ', f1_score(y, model.predict(X), average='macro'), '\\n')\n",
    "print('F1 Micro: ', f1_score(y, model.predict(X), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Árvore de Decisão (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados para teste e treino:\n",
    "X = dadosTreinoBalanceados.drop([85], axis=1)\n",
    "y = dadosTreinoBalanceados[85]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# Criação e treino do modelo da Árvore de Decisão:\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "dt_pred = model.predict(X)\n",
    "\n",
    "# Aplicação da validação cruzada K-Fold:\n",
    "kfold_validation = KFold(10)\n",
    "result = cross_val_score(model, X_test, y_test, cv = kfold_validation)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', result)\n",
    "print('\\nMédia dos resultados:', np.mean(result))\n",
    "print('\\nPredições feitas:\\n', dt_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "c_matrix = confusion_matrix(y, model.predict(X))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', c_matrix[0, 0] / sum(c_matrix[0, :]), '\\n')\n",
    "print('Precisão (Precision): ', c_matrix[0, 0] / sum(c_matrix[:, 0]), '\\n')\n",
    "print('Especificidade (Specificity): ', c_matrix[1, 1] / sum(c_matrix[1, :]), '\\n')\n",
    "print('F1 Macro: ', f1_score(y, model.predict(X), average='macro'), '\\n')\n",
    "print('F1 Micro: ', f1_score(y, model.predict(X), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados para teste e treino:\n",
    "X = dadosTreinoBalanceados.drop([85], axis=1)\n",
    "y = dadosTreinoBalanceados[85]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# Criação e treino do modelo Naive Bayes:\n",
    "model = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "model.fit(X_train, y_train)\n",
    "nb_pred = model.predict(X)\n",
    "\n",
    "# Aplicação da validação cruzada K-Fold:\n",
    "kfold_validation = KFold(10)\n",
    "result = cross_val_score(model, X_test, y_test, cv = kfold_validation)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', result)\n",
    "print('\\nMédia dos resultados:', np.mean(result))\n",
    "print('\\nPredições feitas:\\n', nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "c_matrix = confusion_matrix(y, model.predict(X))\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', c_matrix[0, 0] / sum(c_matrix[0, :]), '\\n')\n",
    "print('Precisão (Precision): ', c_matrix[0, 0] / sum(c_matrix[:, 0]), '\\n')\n",
    "print('Especificidade (Specificity): ', c_matrix[1, 1] / sum(c_matrix[1, :]), '\\n')\n",
    "print('F1 Macro: ', f1_score(y, model.predict(X), average='macro'), '\\n')\n",
    "print('F1 Micro: ', f1_score(y, model.predict(X), average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04eeb17173dda19b79ef31ce2f9124539f6d3d7f6428065f88e9861f21898bc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
